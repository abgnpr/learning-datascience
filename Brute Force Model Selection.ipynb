{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de051708-a27b-415d-a262-502614901bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8227aa3f-e8f0-4d3a-a0ea-28efbb436a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87add910-795f-46fb-8fda-43fbce023a82",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 103 (Temp/ipykernel_15400/3964490679.py, line 104)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\1987698\\AppData\\Local\\Temp/ipykernel_15400/3964490679.py\"\u001b[1;36m, line \u001b[1;32m104\u001b[0m\n\u001b[1;33m    plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\",\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 103\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor, AdaBoostClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet, SGDClassifier, SGDRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# steps\n",
    "# Remove columns with no impact\n",
    "# Boxplot\n",
    "# Filter iqr\n",
    "# Filter thresh\n",
    "# Impute\n",
    "# Encode\n",
    "# Standardise (SVM, linear regression, k-means)\n",
    "# Normalize (KNN)\n",
    "\n",
    "# filter IQR\n",
    "\n",
    "import pandas as pd\n",
    "# Assuming 'df' is your DataFrame and 'column_name' is the column you're analyzing\n",
    "Q1 = df['column_name'].quantile(0.25)\n",
    "Q3 = df['column_name'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Filter out the outliers\n",
    "filtered_df = df[(df['column_name'] >= Q1 - 1.5 * IQR) & (df['column_name'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "classifier_models = [\n",
    "DecisionTreeClassifier(),\n",
    "RandomForestClassifier(),\n",
    "GradientBoostingClassifier(),\n",
    "AdaBoostClassifier(),\n",
    "SVC(),\n",
    "KNeighborsClassifier(),\n",
    "GaussianNB(),\n",
    "LogisticRegression(),\n",
    "SGDClassifier(),\n",
    "MLPClassifier()\n",
    "]\n",
    "\n",
    "regressor_models = [\n",
    "LinearRegression(),\n",
    "Ridge(),\n",
    "Lasso(),\n",
    "ElasticNet(),\n",
    "DecisionTreeRegressor(),\n",
    "RandomForestRegressor(),\n",
    "GradientBoostingRegressor(),\n",
    "SVR(),\n",
    "KNeighborsRegressor(),\n",
    "SGDRegressor(),\n",
    "MLPRegressor()\n",
    "]\n",
    "\n",
    "scores = pd.Series()\n",
    "for model in classifier_models:\n",
    "    scores[model.__class__.__name__] = np.round(cross_val_score(model, X, y, cv=5).mean(), 3)\n",
    "\n",
    "scores\n",
    "\n",
    "\n",
    "# grid search\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(100, 1000, 100),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=7)\n",
    "grid.fit(X,Y)\n",
    "grid.best_params_\n",
    "\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "# Example true labels and predicted labels\n",
    "true_labels = [0, 1, 1, 0, 1, 0, 0, 1, 1, 0]\n",
    "predicted_labels = [0, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "# Create a figure and a subplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "# Set ticks for classes\n",
    "classes = ['Not Spam', 'Spam']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "# Display values in the matrix\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\",\n",
    "color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec92dc6-8b8b-4828-a7d7-0663d446a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor, AdaBoostClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet, SGDClassifier, SGDRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "classifier_models = [\n",
    "    # DecisionTreeClassifier(),\n",
    "    # RandomForestClassifier(),\n",
    "    # GradientBoostingClassifier(),\n",
    "    # AdaBoostClassifier(),\n",
    "    # SVC(),\n",
    "    # KNeighborsClassifier(),\n",
    "    # GaussianNB(),\n",
    "    # LogisticRegression(),\n",
    "    # SGDClassifier(),\n",
    "    # MLPClassifier()\n",
    "]\n",
    "\n",
    "regressor_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    KNeighborsRegressor(),\n",
    "    SGDRegressor(),\n",
    "    MLPRegressor()\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for model in regressor_models:\n",
    "    print(f'{model.__class__.__name__}: {np.round(cross_val_score(model, X, y, cv=kf, n_jobs=None).mean(), 3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
